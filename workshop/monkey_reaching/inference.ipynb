{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eedd905e-6f6a-4104-bd69-5687613696f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"  # export OMP_NUM_THREADS=4\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"8\"  # export OPENBLAS_NUM_THREADS=4\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"8\"  # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"8\"  # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"8\"  # export NUMEXPR_NUM_THREADS=6\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xfads.utils as utils\n",
    "import xfads.prob_utils as prob_utils\n",
    "import pytorch_lightning as lightning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from xfads.ssm_modules.likelihoods import PoissonLikelihood\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianDynamics\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianInitialCondition\n",
    "from xfads.ssm_modules.encoders import LocalEncoderLRMvn, BackwardEncoderLRMvn\n",
    "from xfads.smoothers.lightning_trainers import LightningNonlinearSSM, LightningMonkeyReaching\n",
    "from xfads.smoothers.nonlinear_smoother import NonlinearFilter, LowRankNonlinearStateSpaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914c90da-1011-4abb-aa6e-f07a06d4eb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f796df75-7ced-41bf-8642-b3911d2eef4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initialize(version_base=None, config_path=\"\", job_name=\"monkey_reaching\")\n",
    "cfg = compose(config_name=\"config\")\n",
    "\n",
    "n_bins_bhv = 10\n",
    "seeds = [1234, 1235, 1236]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b70d63fc-3280-405b-b70f-8bbacc46006d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1234\n",
      "Seed set to 1235\n",
      "Seed set to 1236\n"
     ]
    }
   ],
   "source": [
    "\"\"\"config\"\"\"\n",
    "\n",
    "for seed in seeds:\n",
    "    cfg.seed = seed\n",
    "\n",
    "    lightning.seed_everything(cfg.seed, workers=True)\n",
    "    torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1f7f93-1309-47f7-9e5b-04f9d73b7537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"data\"\"\"\n",
    "\n",
    "data_path = 'data/data_{split}_{bin_sz_ms}ms.pt'\n",
    "\n",
    "train_data = torch.load(data_path.format(split='train', bin_sz_ms=cfg.bin_sz_ms))\n",
    "val_data = torch.load(data_path.format(split='valid', bin_sz_ms=cfg.bin_sz_ms))\n",
    "test_data = torch.load(data_path.format(split='test', bin_sz_ms=cfg.bin_sz_ms))\n",
    "\n",
    "y_valid_obs = val_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_train_obs = train_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "y_test_obs = test_data['y_obs'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "vel_valid = val_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_train = train_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "vel_test = test_data['velocity'].type(torch.float32).to(cfg.data_device)\n",
    "\n",
    "n_trials, n_time_bins, n_neurons_obs = y_train_obs.shape\n",
    "n_time_bins_enc = train_data['n_time_bins_enc']\n",
    "\n",
    "y_train_dataset = torch.utils.data.TensorDataset(y_train_obs, vel_train)\n",
    "y_val_dataset = torch.utils.data.TensorDataset(y_valid_obs, vel_valid)\n",
    "y_test_dataset = torch.utils.data.TensorDataset(y_test_obs, vel_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(y_train_dataset, batch_size=cfg.batch_sz, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(y_val_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(y_test_dataset, batch_size=y_valid_obs.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30166f06-94a9-4820-89f5-48d71c75a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"likelihood pdf\"\"\"\n",
    "H = utils.ReadoutLatentMask(cfg.n_latents, cfg.n_latents_read)\n",
    "readout_fn = nn.Sequential(H, nn.Linear(cfg.n_latents_read, n_neurons_obs))\n",
    "readout_fn[-1].bias.data = prob_utils.estimate_poisson_rate_bias(train_dataloader, cfg.bin_sz)\n",
    "likelihood_pdf = PoissonLikelihood(readout_fn, n_neurons_obs, cfg.bin_sz, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42cb5084-2fbc-4d8c-8c04-ed1518817bfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"dynamics module\"\"\"\n",
    "Q_diag = 1. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "dynamics_fn = utils.build_gru_dynamics_function(cfg.n_latents, cfg.n_hidden_dynamics, device=cfg.device)\n",
    "dynamics_mod = DenseGaussianDynamics(dynamics_fn, cfg.n_latents, Q_diag, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3e7abb3-a33e-45e2-b7de-991a491d43de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"initial condition\"\"\"\n",
    "m_0 = torch.zeros(cfg.n_latents, device=cfg.device)\n",
    "Q_0_diag = 1. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "initial_condition_pdf = DenseGaussianInitialCondition(cfg.n_latents, m_0, Q_0_diag, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f351f5fc-096c-43a8-a4b6-7592c5d5c550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"local/backward encoder\"\"\"\n",
    "backward_encoder = BackwardEncoderLRMvn(cfg.n_latents, cfg.n_hidden_backward, cfg.n_latents,\n",
    "                                        rank_local=cfg.rank_local, rank_backward=cfg.rank_backward,\n",
    "                                        device=cfg.device)\n",
    "local_encoder = LocalEncoderLRMvn(cfg.n_latents, n_neurons_obs, cfg.n_hidden_local, cfg.n_latents, rank=cfg.rank_local,\n",
    "                                  device=cfg.device, dropout=cfg.p_local_dropout)\n",
    "nl_filter = NonlinearFilter(dynamics_mod, initial_condition_pdf, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36f2292a-d44a-4812-8116-417765a77c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"sequence vae\"\"\"\n",
    "ssm = LowRankNonlinearStateSpaceModel(dynamics_mod, likelihood_pdf, initial_condition_pdf, backward_encoder,\n",
    "                                      local_encoder, nl_filter, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe90f7c8-e43e-4203-bce4-61f500ded926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"lightning\"\"\"\n",
    "seq_vae = LightningMonkeyReaching(ssm, cfg, n_time_bins_enc, n_bins_bhv)\n",
    "csv_logger = CSVLogger('logs/smoother/acausal/', name=f'sd_{cfg.seed}_r_y_{cfg.rank_local}_r_b_{cfg.rank_backward}', version='smoother_acausal')\n",
    "ckpt_callback = ModelCheckpoint(save_top_k=3, monitor='r2_valid_enc', mode='max', dirpath='ckpts/smoother/acausal/', save_last=True,\n",
    "                                filename='{epoch:0}_{valid_loss:0.2f}_{r2_valid_enc:0.2f}_{r2_valid_bhv:0.2f}_{valid_bps_enc:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33aa2ac1-ac42-421c-b8a3-bc60460e944d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = lightning.Trainer(max_epochs=cfg.n_epochs,\n",
    "                            gradient_clip_val=1.0,\n",
    "                            default_root_dir='lightning/',\n",
    "                            callbacks=[ckpt_callback],\n",
    "                            logger=csv_logger,\n",
    "                            strategy='ddp_notebook',\n",
    "                            accelerator='cpu',\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4a4da3b-5807-4e9f-a46e-f58909cefa3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 1236\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory logs/smoother/acausal/sd_1236_r_y_2_r_b_2/smoother_acausal exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /Users/mahmoud/catnip/xfads/workshop/monkey_reaching/ckpts/smoother/acausal exists and is not empty.\n",
      "\n",
      "  | Name | Type                            | Params\n",
      "---------------------------------------------------------\n",
      "0 | ssm  | LowRankNonlinearStateSpaceModel | 52.0 K\n",
      "---------------------------------------------------------\n",
      "52.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "52.0 K    Total params\n",
      "0.208     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14%|█▍        | 2/14 [00:04<00:27,  0.44it/s, v_num=usal]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=seq_vae, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "torch.save(ckpt_callback.best_model_path, 'ckpts/smoother/acausal/best_model_path.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "421254c0-d385-4c18-8ef1-b401ba5698ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 1236\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:63190 (errno: 48 - Address already in use).\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:63190 (errno: 48 - Address already in use).\n",
      "[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n    results = self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 943, in _run\n    self.strategy.setup_environment()\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\", line 154, in setup_environment\n    self.setup_distributed()\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n    _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/lightning_fabric/utilities/distributed.py\", line 291, in _init_dist_connection\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n    func_return = func(*args, **kwargs)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1177, in init_process_group\n    store, rank, world_size = next(rendezvous_iterator)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/distributed/rendezvous.py\", line 246, in _env_rendezvous_handler\n    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/distributed/rendezvous.py\", line 174, in _create_c10d_store\n    return TCPStore(\ntorch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:63190 (errno: 48 - Address already in use). The server socket has failed to bind to 0.0.0.0:63190 (errno: 48 - Address already in use).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:754\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:144\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m process_context \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mstart_processes(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapping_function,\n\u001b[1;32m    138\u001b[0m     args\u001b[38;5;241m=\u001b[39mprocess_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we will join ourselves to get the process references\u001b[39;00m\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mprocess_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    147\u001b[0m worker_output \u001b[38;5;241m=\u001b[39m return_queue\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:158\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    156\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    157\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 794, in _test_impl\n    results = self._run(model, ckpt_path=ckpt_path)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 943, in _run\n    self.strategy.setup_environment()\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\", line 154, in setup_environment\n    self.setup_distributed()\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n    _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/lightning_fabric/utilities/distributed.py\", line 291, in _init_dist_connection\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/distributed/c10d_logger.py\", line 86, in wrapper\n    func_return = func(*args, **kwargs)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 1177, in init_process_group\n    store, rank, world_size = next(rendezvous_iterator)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/distributed/rendezvous.py\", line 246, in _env_rendezvous_handler\n    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n  File \"/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/torch/distributed/rendezvous.py\", line 174, in _create_c10d_store\n    return TCPStore(\ntorch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:63190 (errno: 48 - Address already in use). The server socket has failed to bind to 0.0.0.0:63190 (errno: 48 - Address already in use).\n"
     ]
    }
   ],
   "source": [
    "trainer.test(dataloaders=test_dataloader, ckpt_path='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af4e15-ef04-46c7-ab00-dabcdf0fd778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfads",
   "language": "python",
   "name": "xfads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
