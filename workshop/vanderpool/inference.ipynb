{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93a76195-f3aa-4ff3-b6f4-2dba07c83f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra import compose, initialize\n",
    "    \n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as lightning\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint \n",
    "\n",
    "import xfads.utils as utils\n",
    "\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianDynamics\n",
    "from xfads.ssm_modules.likelihoods import GaussianLikelihood\n",
    "from xfads.smoothers.lightning_trainers import LightningNonlinearSSM\n",
    "from xfads.ssm_modules.dynamics import DenseGaussianInitialCondition\n",
    "from xfads.ssm_modules.encoders import LocalEncoderLRMvn, BackwardEncoderLRMvn\n",
    "from xfads.smoothers.nonlinear_smoother_causal import NonlinearFilter, LowRankNonlinearStateSpaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a4d6c23-a20e-411c-9f9f-f545674527e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f71e04c4-7c5c-4952-9bac-f6206078f72e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GlobalHydra is already initialized, call GlobalHydra.instance().clear() if you want to re-initialize",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"config\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m cfg \u001b[38;5;241m=\u001b[39m compose(config_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m lightning\u001b[38;5;241m.\u001b[39mseed_everything(cfg\u001b[38;5;241m.\u001b[39mseed, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/hydra/initialize.py:91\u001b[0m, in \u001b[0;36minitialize.__init__\u001b[0;34m(self, config_path, job_name, caller_stack_depth, version_base)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     job_name \u001b[38;5;241m=\u001b[39m detect_task_name(\n\u001b[1;32m     88\u001b[0m         calling_file\u001b[38;5;241m=\u001b[39mcalling_file, calling_module\u001b[38;5;241m=\u001b[39mcalling_module\n\u001b[1;32m     89\u001b[0m     )\n\u001b[0;32m---> 91\u001b[0m \u001b[43mHydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_main_hydra_file_or_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalling_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalling_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcalling_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalling_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/hydra/_internal/hydra.py:53\u001b[0m, in \u001b[0;36mHydra.create_main_hydra_file_or_module\u001b[0;34m(cls, calling_file, calling_module, config_path, job_name)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_main_hydra_file_or_module\u001b[39m(\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHydra\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     job_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     48\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHydra\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     49\u001b[0m     config_search_path \u001b[38;5;241m=\u001b[39m create_automatic_config_search_path(\n\u001b[1;32m     50\u001b[0m         calling_file, calling_module, config_path\n\u001b[1;32m     51\u001b[0m     )\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_main_hydra2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_search_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/hydra/_internal/hydra.py:68\u001b[0m, in \u001b[0;36mHydra.create_main_hydra2\u001b[0;34m(cls, task_name, config_search_path)\u001b[0m\n\u001b[1;32m     65\u001b[0m hydra \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(task_name\u001b[38;5;241m=\u001b[39mtask_name, config_loader\u001b[38;5;241m=\u001b[39mconfig_loader)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglobal_hydra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalHydra\n\u001b[0;32m---> 68\u001b[0m \u001b[43mGlobalHydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhydra\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hydra\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/hydra/core/global_hydra.py:16\u001b[0m, in \u001b[0;36mGlobalHydra.initialize\u001b[0;34m(self, hydra)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hydra, Hydra), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected Hydra type : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(hydra)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_initialized():\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlobalHydra is already initialized, call GlobalHydra.instance().clear() if you want to re-initialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhydra \u001b[38;5;241m=\u001b[39m hydra\n",
      "\u001b[0;31mValueError\u001b[0m: GlobalHydra is already initialized, call GlobalHydra.instance().clear() if you want to re-initialize"
     ]
    }
   ],
   "source": [
    "\"\"\"config\"\"\"\n",
    "\n",
    "initialize(version_base=None, config_path=\"\", job_name=\"lds\")\n",
    "cfg = compose(config_name=\"config\")\n",
    "lightning.seed_everything(cfg.seed, workers=True)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ba708e1-5816-4340-9780-3c96ca8fea31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"generate data -- 2d oscillator with decay\"\"\"\n",
    "\n",
    "n_trials = 500\n",
    "n_neurons = 100\n",
    "n_time_bins = 250\n",
    "\n",
    "C = utils.FanInLinear(cfg.n_latents, n_neurons, device=cfg.device).requires_grad_(False)\n",
    "Q_diag = 1e-3 * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "Q_0_diag = 2. * torch.ones(cfg.n_latents, device=cfg.device)\n",
    "R_diag = 1e-1 * torch.ones(n_neurons, device=cfg.device)\n",
    "m_0 = torch.zeros(cfg.n_latents, device=cfg.device)\n",
    "\n",
    "mean_fn = utils.VdpDynamicsModel()\n",
    "\n",
    "z = utils.sample_gauss_z(mean_fn, Q_diag, m_0, Q_0_diag, n_trials, n_time_bins)\n",
    "y = C(z) + torch.sqrt(R_diag) * torch.randn((n_trials, n_time_bins, n_neurons), device=cfg.device)\n",
    "y = y.detach()\n",
    "\n",
    "y_train, z_train = y[:2*n_trials//3], z[:2*n_trials//3]\n",
    "y_valid, z_valid = y[2*n_trials//3:], z[2*n_trials//3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "533c8934-1d0c-44b1-964f-aeddd538e30e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_dataset = torch.utils.data.TensorDataset(y_train,)\n",
    "y_valid_dataset = torch.utils.data.TensorDataset(y_valid,)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    y_train_dataset,\n",
    "    batch_size=cfg.batch_sz,\n",
    "    shuffle=True,\n",
    "    num_workers=9\n",
    ")\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    y_valid_dataset,\n",
    "    batch_size=cfg.batch_sz,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78f2f94f-e07c-4743-8217-baebe5fd1498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"likelihood pdf\"\"\"\n",
    "\n",
    "likelihood_pdf = GaussianLikelihood(C, n_neurons, R_diag, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a642862-60f5-4b31-843c-9948a23ec718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"dynamics module\"\"\"\n",
    "\n",
    "dynamics_fn = utils.build_gru_dynamics_function(cfg.n_latents, cfg.n_hidden_dynamics, device=cfg.device)\n",
    "dynamics_mod = DenseGaussianDynamics(dynamics_fn, cfg.n_latents, Q_diag, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f6e51ba-e9e4-446b-81f5-3173cd33ced3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"initial condition\"\"\"\n",
    "\n",
    "initial_condition_pdf = DenseGaussianInitialCondition(cfg.n_latents, m_0, Q_0_diag, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d8483e4-1b0b-45f7-a977-715460114603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"local/backward encoder\"\"\"\n",
    "\n",
    "backward_encoder = BackwardEncoderLRMvn(cfg.n_latents, cfg.n_hidden_backward, cfg.n_latents,\n",
    "                                        rank_local=cfg.rank_local, rank_backward=cfg.rank_backward,\n",
    "                                        device=cfg.device)\n",
    "\n",
    "local_encoder = LocalEncoderLRMvn(cfg.n_latents, n_neurons, cfg.n_hidden_local, cfg.n_latents, rank=cfg.rank_local,\n",
    "                                  device=cfg.device, dropout=cfg.p_local_dropout)\n",
    "\n",
    "nl_filter = NonlinearFilter(dynamics_mod, initial_condition_pdf, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6934f306-1222-4cf9-b828-36c562ec89b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"sequence vae\"\"\"\n",
    "\n",
    "ssm = LowRankNonlinearStateSpaceModel(dynamics_mod, likelihood_pdf, initial_condition_pdf, backward_encoder,\n",
    "                                      local_encoder, nl_filter, device=cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cba5887-c8e3-453d-adf3-dfe58a347532",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "\"\"\"lightning\"\"\"\n",
    "\n",
    "seq_vae = LightningNonlinearSSM(ssm, cfg)\n",
    "\n",
    "csv_logger = CSVLogger('logs/', name=f'r_y_{cfg.rank_local}_r_b_{cfg.rank_backward}', version='noncausal')\n",
    "ckpt_callback = ModelCheckpoint(save_top_k=3, monitor='valid_loss', mode='min', dirpath='ckpts/',\n",
    "                                filename='{epoch:0}_{valid_loss}')\n",
    "\n",
    "trainer = lightning.Trainer(max_epochs=cfg.n_epochs,\n",
    "                            gradient_clip_val=1.0,\n",
    "                            default_root_dir='lightning/',\n",
    "                            callbacks=[ckpt_callback],\n",
    "                            logger=csv_logger\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "064da6d6-1382-4dd3-a4be-ec84ee81937d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name | Type                            | Params\n",
      "---------------------------------------------------------\n",
      "0 | ssm  | LowRankNonlinearStateSpaceModel | 41.3 K\n",
      "---------------------------------------------------------\n",
      "41.0 K    Trainable params\n",
      "300       Non-trainable params\n",
      "41.3 K    Total params\n",
      "0.165     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=seq_vae, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "torch.save(ckpt_callback.best_model_path, 'ckpts/best_model_path.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b618fdb0-e91a-477d-98af-43249cb476a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`Trainer.test()` requires a `LightningModule` when it hasn't been passed in a previous run",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xfads/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:744\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;66;03m# do we still have a reference from a previous call?\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    745\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Trainer.test()` requires a `LightningModule` when it hasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt been passed in a previous run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    746\u001b[0m         )\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n",
      "\u001b[0;31mTypeError\u001b[0m: `Trainer.test()` requires a `LightningModule` when it hasn't been passed in a previous run"
     ]
    }
   ],
   "source": [
    "trainer.test(dataloaders=valid_dataloader, ckpt_path='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41024acb-7d04-4c8e-894b-b7767e32b1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfads",
   "language": "python",
   "name": "xfads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
